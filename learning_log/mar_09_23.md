# 3/9/2023

## Deep Learning Concepts

### Machine Learning Fundamentals (2023 version)

#### Topics Covered Today

- **What is machine learning?**
    - A subset of AI that enables computers to learn from data
    - ML systems are trained rather than programmed
    - Goal of ML is to max performance on unseen data. That is to generalize.
- **Different types of ML (supervised, unsupervised, semi-supervised, self-supervise, reinforcement learning)**
    - Supervised: data is labeled, you have the x's and y's, regression/classification
    - Unsupervised: we only have the x's, clustering, anomaly detection, dimensionality reduction, looking for underlining pattern in the input data to reduce it
    - Semi-Supervised: Combo of previous two, you have some x's matched to y's but not all, and in fact you will have many more x's than you will y's to establish meta-labels
    - Self-Supervised: Type of unsupervised, used in deep learning more
    - Reinforcement Learning: Agents can interact with enviorment, buy/sell/hold, and based on reward you will get feedback, creates policy function to dicate bahavior
- **The Model**
    - Composed of
        - y's or responses. dependent var, our TARGET
        - x's predictor, indepen var, our FEATURES
        - _theta_, our estimates , specifications, PARAMETERS
    - Purpose is to estimate a function for:
        - Inference (interpretable ML)
        - Prediction
- **Performance Metrics**
    - For Regression
        - MAE (Mean Abs Error), MSE (Mean sq error), RMSE (Root MSE), RMSLE (Root Mean Sq Error Log error), R^2 and Adjusted R^2
    - For Classification
        - Confusion Matrix, Accuracy, Precision and Recall, F-Score, AUC-ROC, Log Loss, Gini Coef
- **Bias Variance Trade Off - Optimization vs Generalization**
    - Generally want to have low bias and low variance
    - Underfitting is from too simple (high bias)
    - Overfitting is from too complex (high variance)
- **Overfitting**
    - When it doesn't generalize to new data
    - Fits training data too well
    - Happens when model is too complex
- **Mitigating Overfitting**
    - Collect more data (can reduce bias and variance)
    - Complexity Reduction (regularization)
    - Cross validation
- **Partitioning the Data (train, validation, test)**
    - Training Set: What trains the model (60%-80%)
    - Validation Set: To validate and tune model (0-20%)
    - Test Set: To test model's ability to predict (20%)
    - For larger data sets can reduce test size
- **Resampling Methods**
    - When can't afford to split data into three, you can skip the validation set and fold it into the training set, hence the 0-20% 
    - Most common way to do this is _Cross Fold Validation_
- **k-fold Cross Validation**
    - Divide training data into K equal sized mutually exclusive subsets
    - Leave out the kth fold and fit the model to the remaining k-1 folds
    - Obtain prediction for kth fold
    - Repeat for all k parts, results are then combined
    - Computationally expensive
- **Why do we need to do cross validation?**
    - Model architecture selection (optimization vs generalization)
    - Estimation of Model Performance in the test set
    - After selecting best mnodel architecture we estimate the generalization error using test set
    - Different model Comparison is based on test set performance
- **Learning curve**
    - These are plots of how training data and performance effect the ML model
    - used to diagnose bias and variance levels looking for "goldilocks"
- **Learning, Cost Function and Gradient Descent**
    - Learning: Finding the model weights (parameters's values)
    - Cost Function: "How good" our model is at marking predictions for a given set of parameters
        - Cost function will have its own graph and gradients. the slope of this curve tells us how to upate our parameters to make the model more accurate.
    - Gradient Descent (GD): Used when cost function is continuous and differnetiable
        - Iterative Optimization Algo for finding the min of a function
        - Starts at a random point and takes seteps proportional to the negative of the gradient at that point
        - Choice of learning rate, if _a_ too small GD can be slow, _a_ too large the GD can diverge
    - Stochastic GD: Use case same as GD
- **Why should we go beyond gradient descent?**
    - Disadvantages of GD
        - use entire training set to update parameters
        - sensitive to choice of learning rate
        - slow for large data
    - Solution?
        - Minibatch (aka stochastic GD), which speeds things up using smaller batches of training data
- **Why should we go beyond stochastic gradient descent? momentum?**
    - for deep learning
    - when loss functions can be difficult to optimize
    - Solution?
        - Designing an adaptive learning rate that can adapt to the loss landscape
- **Putting it together, _How do machines actually learn?_**
    - By optimizing cost functions
    - ![machine leaning diagram](../learning_log/assets/Screenshot%202023-03-09%20142913.png)
  
### Take Away
    - My god there is a lot to take in, interesting to see what Code Fellows had time to teach us about these concepts and what this guy went into. I don't feel like CF did bad, def prepped me for this along with some other previous exposure, but so much more in depth here about training and test size, and methods. 